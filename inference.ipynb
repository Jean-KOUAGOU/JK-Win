{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "generous-curtis",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bibliographic-slope",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bibliographic-panic",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"bbdc_2023_AWI_data_develop_professional.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "charitable-jerusalem",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_cols = df_train.columns[0].split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "executed-patrol",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_values = list(map(lambda x: x[0].split(';'), df_train.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arabic-nirvana",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_clean = pd.DataFrame(clean_values[1:], columns=clean_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "proprietary-decrease",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_clean[\"Datum\"] = pd.to_datetime(df_train_clean[\"Datum\"], yearfirst=True, dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "assigned-singer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fix_format(string):\n",
    "    return string.strip(\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caring-retailer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "select = df_train_clean[\"NOx\"] != \"NA\"\n",
    "select_no3 = df_train_clean[\"NO3\"] != \"NA\"\n",
    "select_no2 = df_train_clean[\"NO2\"] != \"NA\"\n",
    "select_nh4 = df_train_clean[\"NH4\"] != \"NA\"\n",
    "select_sio4 = df_train_clean[\"SiO4\"] != \"NA\"\n",
    "select_sal = df_train_clean[\"Salinität\"] != \"NA\"\n",
    "select_temp = df_train_clean[\"Temperatur\"] != \"NA\"\n",
    "select_sec = df_train_clean[\"SECCI\"] != \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "executive-brown",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NOx = df_train_clean[\"NOx\"].apply(fix_format)[select].values.astype(float)\n",
    "NO3 = df_train_clean[\"NO3\"].apply(fix_format)[select & select_no3].values.astype(float)\n",
    "NO2 = df_train_clean[\"NO2\"].apply(fix_format)[select & select_no2].values.astype(float)\n",
    "NH4 = df_train_clean[\"NH4\"].apply(fix_format)[select & select_nh4].values.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "optical-heater",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "deg = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "earlier-vacation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interpolate(data1, data2, select, degree=deg):\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    values1, values2 = data1[select].values.astype(float), data2[select].values.astype(float)\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    poly_features = poly.fit_transform(values1)\n",
    "    poly_reg_model = LinearRegression()\n",
    "    poly_reg_model.fit(poly_features, values2)\n",
    "    return poly_reg_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-cliff",
   "metadata": {},
   "source": [
    "Model NO3, NO2 and NH4 as a function of Temperatur and Salinitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "proved-warehouse",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_no3 = df_train_clean[\"NO3\"].apply(fix_format)\n",
    "target_no2 = df_train_clean[\"NO2\"].apply(fix_format)\n",
    "target_nh4 = df_train_clean[\"NH4\"].apply(fix_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "general-charles",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_temp_sal = pd.concat([df_train_clean[\"Temperatur\"].apply(fix_format), df_train_clean[\"Salinität\"].apply(fix_format)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minor-twelve",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_no3 = interpolate(data_temp_sal, target_no3, select_temp & select_sal & select_no3, degree=deg)\n",
    "model_no2 = interpolate(data_temp_sal, target_no2, select_temp & select_sal & select_no2, degree=deg)\n",
    "model_nh4 = interpolate(data_temp_sal, target_nh4, select_temp & select_sal & select_nh4, degree=deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fundamental-buyer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_with_temp_sal(df, model, select, col_name=\"NO3\"):\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    poly = PolynomialFeatures(degree=deg)\n",
    "    for c, (bl, row) in enumerate(zip(select.values, df.iterrows())):\n",
    "        if bl:\n",
    "            poly_features = poly.fit_transform(np.array([row[-1][\"Temperatur\"].strip(\"?\"), row[-1][\"Salinität\"].strip(\"?\")], dtype=float).reshape(1,-1))\n",
    "            pred = model.predict(poly_features)\n",
    "            df.loc[c, col_name] = str(pred[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "immune-apple",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_with_temp_sal(df_train_clean, model_no3, select_temp & select_sal & ~select_no3, col_name=\"NO3\");\n",
    "predict_with_temp_sal(df_train_clean, model_no2, select_temp & select_sal & ~select_no2, col_name=\"NO2\");\n",
    "predict_with_temp_sal(df_train_clean, model_nh4, select_temp & select_sal & ~select_nh4, col_name=\"NH4\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afraid-mistress",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "select_no3 = df_train_clean[\"NO3\"] != \"NA\"\n",
    "select_no2 = df_train_clean[\"NO2\"] != \"NA\"\n",
    "select_nh4 = df_train_clean[\"NH4\"] != \"NA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "operating-tomato",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_nox = pd.concat([df_train_clean[\"NO3\"].apply(fix_format), df_train_clean[\"NO2\"].apply(fix_format),\n",
    "                          df_train_clean[\"NH4\"].apply(fix_format)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "forbidden-diagram",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_nox = df_train_clean[\"NOx\"].apply(fix_format)\n",
    "target_secci = df_train_clean[\"SECCI\"].apply(fix_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "promising-simpson",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_nox = interpolate(features_nox, target_nox, select_no3 & select_no2 & select_nh4 & select, degree=deg)\n",
    "model_secci = interpolate(features_nox, target_secci, select_no3 & select_no2 & select_nh4 & select_sec, degree=deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "chicken-hardwood",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model_nox.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "covered-option",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_clean[\"NOx\"].apply(fix_format)[select_no3 & select_no2 & select_nh4 & select].values.astype(float);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rubber-capacity",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_clean[\"SECCI\"].apply(fix_format)[select_no3 & select_no2 & select_nh4 & select_sec].values.astype(float);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "educational-bundle",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=deg)\n",
    "poly_features = poly.fit_transform(features_nox[select_no3 & select_no2 & select_nh4 & select].values.astype(float))\n",
    "pred_nox = model_nox.predict(poly_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "expired-aluminum",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=deg)\n",
    "poly_features = poly.fit_transform(features_nox[select_no3 & select_no2 & select_nh4 & select_sec].values.astype(float))\n",
    "pred_secci = model_secci.predict(poly_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "unknown-miniature",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_nox;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "typical-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_secci;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-clark",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "prostate-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_missing_nox(df, model, select):\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    poly = PolynomialFeatures(degree=deg)\n",
    "    for c, (bl, row) in enumerate(zip(select.values, df.iterrows())):\n",
    "        if bl:\n",
    "            assert row[-1][\"NOx\"] == \"NA\"\n",
    "            poly_features = poly.fit_transform(np.array([row[-1][\"NO3\"].strip(\"?\"), row[-1][\"NO2\"].strip(\"?\"),\n",
    "                                                        row[-1][\"NH4\"].strip(\"?\")], dtype=float).reshape(1,-1))\n",
    "            pred = model.predict(poly_features)\n",
    "            df.loc[c, \"NOx\"] = str(pred[0])\n",
    "    return df\n",
    "\n",
    "def predict_missing_secci(df, model, select):\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    poly = PolynomialFeatures(degree=deg)\n",
    "    for c, (bl, row) in enumerate(zip(select.values, df.iterrows())):\n",
    "        if bl:\n",
    "            assert row[-1][\"SECCI\"] == \"NA\"\n",
    "            poly_features = poly.fit_transform(np.array([row[-1][\"NO3\"].strip(\"?\"), row[-1][\"NO2\"].strip(\"?\"),\n",
    "                                                        row[-1][\"NH4\"].strip(\"?\")], dtype=float).reshape(1,-1))\n",
    "            pred = model.predict(poly_features)\n",
    "            df.loc[c, \"SECCI\"] = str(pred[0])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "reserved-producer",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_missing_nox(df_train_clean, model_nox, select_no3 & select_no2 & select_nh4 & ~select);\n",
    "predict_missing_secci(df_train_clean, model_secci, select_no3 & select_no2 & select_nh4 & ~select_sec);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "binary-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean[select_no3 & select_no2 & select_nh4 & ~select_sec];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-court",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "welcome-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_time(df):\n",
    "    c=0\n",
    "    values = []\n",
    "    for row in tqdm(df['Uhrzeit'], total=len(df)):\n",
    "        try:\n",
    "            pd.to_datetime(row)\n",
    "            values.append(row)\n",
    "        except ValueError:\n",
    "            df_train_clean.loc[c, 'Uhrzeit'] = \"NA\"\n",
    "        c+=1\n",
    "    mean_time = pd.to_datetime(values).mean()\n",
    "    df[\"Uhrzeit\"] = df[\"Uhrzeit\"].replace(\"NA\", mean_time)\n",
    "    df[\"Uhrzeit\"] = pd.to_datetime(df[\"Uhrzeit\"], yearfirst=True, dayfirst=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "robust-childhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17531/17531 [00:03<00:00, 5154.62it/s]\n",
      "/tmp/ipykernel_96661/2387880895.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  mean_time = pd.to_datetime(values).mean()\n"
     ]
    }
   ],
   "source": [
    "df_train_clean = handle_time(df_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "deluxe-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "north-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_join_date_time(date, time):\n",
    "    def remove_time(dt):\n",
    "        return str(dt).split()[0]\n",
    "    def remove_date(dt):\n",
    "        return str(dt).split()[1]\n",
    "    date_str = date.apply(remove_time)\n",
    "    time_str = time.apply(remove_date)\n",
    "    def final_convert(datetime):\n",
    "        return datetime.replace(':', ',').replace('-', ',')\n",
    "    datetime = (time_str+','+date_str).apply(final_convert)\n",
    "    return datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "circular-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime = convert_join_date_time(df_train_clean['Datum'], df_train_clean['Uhrzeit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "distributed-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean['datetime'] = datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "moral-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean.columns;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "martial-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "thirty-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_numeric(df, col):\n",
    "    values = []\n",
    "    for c, row in enumerate(df[col]):\n",
    "        if row != \"NA\":\n",
    "            values.append(float(row.strip(\"?\")))\n",
    "        try:\n",
    "            float(row)\n",
    "        except ValueError:\n",
    "            df.loc[c, col] = str(row).strip(\"?\")\n",
    "    df[col] = df[col].replace(\"NA\", str(np.mean(values))).astype(float)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "invalid-exclusive",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:05<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(['SECCI', 'Temperatur', 'Salinität', 'NH4', 'NOx', 'NO2', 'NO3', 'PO4', 'SiO4']):\n",
    "    df_train_clean = handle_missing_numeric(df_train_clean, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "attached-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean.drop(['Datum', 'Uhrzeit'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "duplicate-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df_train_clean.columns\n",
    "cols = [cols[-1]]+list(cols[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aggressive-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean = df_train_clean[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "narrow-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "incoming-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_time(string):\n",
    "    if '.' in string:\n",
    "        splits = string.split(',')\n",
    "        splits[2] = splits[2].split('.')[0]\n",
    "        return ','.join(splits)\n",
    "    else:\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "patent-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean['datetime'] = df_train_clean['datetime'].apply(clean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dimensional-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_clean.to_csv('data_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-contribution",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-surname",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "capable-latest",
   "metadata": {},
   "source": [
    "### Load trained models to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "serial-leone",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn, numpy as np, pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "liable-spank",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"bbdc_2023_AWI_data_evaluate_skeleton_professional.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "adequate-stadium",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def handle_time(df):\n",
    "    c=0\n",
    "    values = []\n",
    "    for row in tqdm(df['Uhrzeit'], total=len(df)):\n",
    "        try:\n",
    "            pd.to_datetime(row)\n",
    "            values.append(row)\n",
    "        except ValueError:\n",
    "            df_train_clean.loc[c, 'Uhrzeit'] = \"NA\"\n",
    "        c+=1\n",
    "    mean_time = pd.to_datetime(values).mean()\n",
    "    df[\"Uhrzeit\"] = df[\"Uhrzeit\"].replace(\"NA\", mean_time)\n",
    "    df[\"Uhrzeit\"] = pd.to_datetime(df[\"Uhrzeit\"], yearfirst=True, dayfirst=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fatty-three",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_cols = df_test.columns[0].split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "minimal-nicholas",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_values = list(map(lambda x: x[0].split(';'), df_test.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "foster-logic",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "received-bahamas",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test_clean = pd.DataFrame(test_values[1:], columns=clean_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "unknown-beauty",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test_clean[\"Datum\"] = pd.to_datetime(df_test_clean[\"Datum\"], yearfirst=True, dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dried-active",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1365/1365 [00:00<00:00, 5268.15it/s]\n",
      "/tmp/ipykernel_96661/2387880895.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  mean_time = pd.to_datetime(values).mean()\n",
      "/tmp/ipykernel_96661/2387880895.py:13: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[\"Uhrzeit\"] = pd.to_datetime(df[\"Uhrzeit\"], yearfirst=True, dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "df_test_clean = handle_time(df_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "radical-printing",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_join_date_time(date, time):\n",
    "    def remove_time(dt):\n",
    "        return str(dt).split()[0]\n",
    "    def remove_date(dt):\n",
    "        return str(dt).split()[1]\n",
    "    date_str = date.apply(remove_time)\n",
    "    time_str = time.apply(remove_date)\n",
    "    def final_convert(datetime):\n",
    "        return datetime.replace(':', ',').replace('-', ',')\n",
    "    datetime = (time_str+','+date_str).apply(final_convert)\n",
    "    return datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "elect-windows",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_time(string):\n",
    "    if '.' in string:\n",
    "        splits = string.split(',')\n",
    "        splits[2] = splits[2].split('.')[0]\n",
    "        return ','.join(splits)\n",
    "    else:\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "addressed-hopkins",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test_clean['datetime'] = convert_join_date_time(df_test_clean['Datum'], df_test_clean['Uhrzeit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "universal-continent",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = df_test_clean.columns\n",
    "cols = [cols[-1]]+list(cols[0:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "metallic-brain",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test_clean = df_test_clean[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "tamil-outreach",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test_clean.drop(['Datum', 'Uhrzeit'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "prostate-phrase",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test_clean['datetime'] = df_test_clean['datetime'].apply(clean_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "graphic-radical",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import TestDataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "naked-pioneer",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_test_additional = pd.read_csv('data_test_additional.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "introductory-variation",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_model = torch.load('Date2Vec/models/d2v_cos_14.054091384440834.pth', map_location='cpu').eval()\n",
    "test_dataset = TestDataLoader(df_test_clean, data_test_additional, embedding_model)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, num_workers=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51418957-fa90-4254-b966-2fdf4735f563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dim = 68\n",
    "proj_dim = 64\n",
    "num_heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "white-nebraska",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_models(model_names, all_models=False):\n",
    "    models = []\n",
    "    for m in model_names:\n",
    "        for fold in [0, 1, 2, 3, 4]:\n",
    "            if m == 'SetTransformer':\n",
    "                for num_inds in [4, 8, 16, 32]:\n",
    "                    if num_inds in [8, 16, 32]:\n",
    "                        model = SetTransformer(input_dim, proj_dim, num_inds, 2, 1)\n",
    "                        model.load_state_dict(torch.load(f'trained_models/trained_SetTransformer{num_inds}_fold{fold}.pt', map_location='cuda'))\n",
    "                        model.eval()\n",
    "                        models.append(model.cuda())\n",
    "                    if all_models:\n",
    "                        for num_heads in [2, 4]:\n",
    "                            model = SetTransformer(input_dim, proj_dim, num_inds, num_heads, 1)\n",
    "                            model.load_state_dict(torch.load(f'trained_models/trained_SetTransformer_num_inds{num_inds}_num_heads{num_heads}_fold{fold}.pt', map_location='cuda'))\n",
    "                            model.eval()\n",
    "                            models.append(model.cuda())\n",
    "            elif m == 'GRU':\n",
    "                model = GRU(input_dim, proj_dim, 2)\n",
    "                model.load_state_dict(torch.load(f'trained_models/trained_GRU_fold{fold}.pt', map_location='cuda'))\n",
    "                model.eval()\n",
    "                models.append(model.cuda())\n",
    "                \n",
    "            elif m == 'LSTM':\n",
    "                model = LSTM(input_dim, proj_dim, 2)\n",
    "                model.load_state_dict(torch.load(f'trained_models/trained_LSTM_fold{fold}.pt', map_location='cuda'))\n",
    "                model.eval()\n",
    "                models.append(model.cuda())\n",
    "                    \n",
    "            elif m == 'MLP':\n",
    "                model = MLP(input_dim, proj_dim)\n",
    "                model.load_state_dict(torch.load(f'trained_models/trained_MLP_fold{fold}.pt', map_location='cuda'))\n",
    "                model.eval()\n",
    "                models.append(model.cuda())\n",
    "                    \n",
    "    return models\n",
    "\n",
    "def get_prediction(models, x):\n",
    "    with torch.no_grad():\n",
    "        for i, model in enumerate(models):\n",
    "            if i == 0:\n",
    "                preds = model(x)\n",
    "            else:\n",
    "                preds = preds+model(x)\n",
    "    return preds/len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "gentle-sydney",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Models1 = get_models(['SetTransformer', 'GRU', 'LSTM', 'MLP'], all_models=True)\n",
    "Models = Models1# + Models2\n",
    "All_predictions = []\n",
    "for x in test_dataloader:\n",
    "    x = x.cuda()\n",
    "    preds = get_prediction(Models, x)\n",
    "    All_predictions.append(preds.detach().cpu().numpy())\n",
    "All_predictions = np.concatenate(All_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324499db-9b4d-49af-974b-caf4cf70490c",
   "metadata": {},
   "source": [
    "### Best Predictions (submission 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-neighbor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "union-institution",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df = pd.read_csv(\"bbdc_2023_AWI_data_evaluate_skeleton_professional.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "tested-planning",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = len(eval_df)\n",
    "unique_col = eval_df.columns[0]\n",
    "for i in range(n):\n",
    "    if i != 0:\n",
    "        row = eval_df[unique_col].iloc[i]\n",
    "        eval_df.loc[i, unique_col] = ';'.join(row.split(';')[:2])+';'+';'.join(list(map(str, All_predictions[i-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "active-stamp",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_df.to_csv('prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-african",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "separated-liverpool",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def comparative_plot(preds, prev=9):\n",
    "    import pandas as pd, numpy as np\n",
    "    old_prediction = pd.read_csv(f\"submissions/prediction{prev}.csv\")\n",
    "    old_prediction_values = list(map(lambda x: x[0].split(';')[2:], old_prediction.values))[1:]\n",
    "    old_prediction_values = np.array(old_prediction_values, dtype=float)\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(15,10), constrained_layout=True)\n",
    "    for ax, col_num in zip(axs.flat, list(range(3, 12))):\n",
    "        #ax.plot(crv, mk, markersize=3, linewidth=3, color=c)\n",
    "        ax.plot(preds[:, col_num-3])\n",
    "        ax.plot(old_prediction_values[:, col_num-3])\n",
    "        ax.legend([cols[col_num], cols[col_num]+f\"_prediction{prev}\"])\n",
    "        #plt.legend([cols[col_num], cols[col_num]+\"_prev\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "stuck-venture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparative_plot(All_predictions, 11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jk-win",
   "language": "python",
   "name": "jk-win"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
